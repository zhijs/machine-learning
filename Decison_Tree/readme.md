# 决策树
决策树（Decision Tree）算法是一种基本的分类与回归方法

决策树模型呈树形结构，在分类问题中，表示基于特征对实例进行分类的过程。它可以认为是 if-then 规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布。

决策树是一个预测模型，它代表的是对象属性与对象值之间的一种映射关系


## 决策树步骤
1. 特征选择
2. 决策树的生成
3. 决策树的修剪

决策树是一种十分常用的分类方法，需要监督学习，监管学习就是给出一堆样本，每个样本都有一组属性和一个分类结果，也就是分类结果已知，那么通过学习这些样本得到一个决策树，这个决策树能够对新的数据给出正确的分类


## 信息增益
信息增益表示得知特征X的信息而使得类Y的信息的不确定性减少的程度。

## 工作原理

```
def createBranch():
'''
此处运用了迭代的思想。 感兴趣可以搜索 迭代 recursion， 甚至是 dynamic programing。
'''
    检测数据集中的所有数据的分类标签是否相同:
        If so return 类标签
        Else:
            寻找划分数据集的最好特征（划分之后信息熵最小，也就是信息增益最大的特征）
            划分数据集
            创建分支节点
                for 每个划分的子集
                    调用函数 createBranch （创建分支的函数）并增加返回结果到分支节点中
            return 分支节点

```


## 实战项目1
[使用决策树预测隐形眼镜类型](./dTree_glasses.py)
